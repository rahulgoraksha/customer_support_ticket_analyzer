{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4be615ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Error loading pos_tag: Package 'pos_tag' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import spacy \n",
    "from IPython.display import display, HTML\n",
    "from spacy import displacy\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('pos_tag')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8652c242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>location</th>\n",
       "      <th>email_subject</th>\n",
       "      <th>message_body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>true_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0001</td>\n",
       "      <td>Ryan Obrien</td>\n",
       "      <td>North Billy</td>\n",
       "      <td>Law from traditional now Mrs.</td>\n",
       "      <td>Reflect available century join outside. i cant...</td>\n",
       "      <td>2025-09-01 06:10:59</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0002</td>\n",
       "      <td>Jamie Salazar</td>\n",
       "      <td>South Kari</td>\n",
       "      <td>Require billion probably cut raise include now.</td>\n",
       "      <td>Try cause behind single project. Sport sound c...</td>\n",
       "      <td>2025-06-16 04:58:19</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0003</td>\n",
       "      <td>Clinton Wallace</td>\n",
       "      <td>Port Paige</td>\n",
       "      <td>South maintain year firm.</td>\n",
       "      <td>While travel major strong pull. Us history lig...</td>\n",
       "      <td>2025-08-17 14:54:02</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0004</td>\n",
       "      <td>Christopher Olsen</td>\n",
       "      <td>Jeanville</td>\n",
       "      <td>Fill personal fire.</td>\n",
       "      <td>Can nothing force move free body stand approac...</td>\n",
       "      <td>2025-10-15 06:27:28</td>\n",
       "      <td>Praise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0005</td>\n",
       "      <td>Alex Alexander</td>\n",
       "      <td>West Gail</td>\n",
       "      <td>Term authority offer feeling than.</td>\n",
       "      <td>Control skin fall. Left worker ready take prop...</td>\n",
       "      <td>2025-05-14 22:35:51</td>\n",
       "      <td>Praise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message_id          user_name  ...           created_at    true_category\n",
       "0      M0001        Ryan Obrien  ...  2025-09-01 06:10:59  Feature Request\n",
       "1      M0002      Jamie Salazar  ...  2025-06-16 04:58:19            Other\n",
       "2      M0003    Clinton Wallace  ...  2025-08-17 14:54:02  Feature Request\n",
       "3      M0004  Christopher Olsen  ...  2025-10-15 06:27:28           Praise\n",
       "4      M0005     Alex Alexander  ...  2025-05-14 22:35:51           Praise\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\admin\\\\OneDrive - BOMBAY COATED AND SPECIAL STEELS PRIVATE LIMITED\\\\Desktop\\\\customer_support_ticket_analyzer\\\\data\\\\customer_support_tickets_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de96a70",
   "metadata": {},
   "source": [
    "Load and inspect the dataset (CSV format). Identify\tmissing\tvalues,\tduplicates, and\tcolumn types.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ef741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message_id       0\n",
       "user_name        0\n",
       "location         0\n",
       "email_subject    0\n",
       "message_body     0\n",
       "created_at       0\n",
       "true_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4cf70b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "995    False\n",
       "996    False\n",
       "997    False\n",
       "998    False\n",
       "999    False\n",
       "Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated() # Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01d9a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message_id       object\n",
       "user_name        object\n",
       "location         object\n",
       "email_subject    object\n",
       "message_body     object\n",
       "created_at       object\n",
       "true_category    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # Check data types of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93385ed3",
   "metadata": {},
   "source": [
    "Perform\tdeep text cleaning on 'message_body': remove emojis, HTML, repeated\tpunctuation, extra spaces,and fix common spelling errors.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53e9b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reflect available century join outside. i cant...\n",
       "1    Try cause behind single project. Sport sound c...\n",
       "2    While travel major strong pull. Us history lig...\n",
       "3    Can nothing force move free body stand approac...\n",
       "4    Control skin fall. Left worker ready take prop...\n",
       "Name: message_body, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "#remove the emojis\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "df['message_body'] = df['message_body'].apply(remove_emojis)\n",
    "df['message_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "550f4fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reflect available century join outside. i cant...\n",
       "1    Try cause behind single project. Sport sound c...\n",
       "2    While travel major strong pull. Us history lig...\n",
       "3    Can nothing force move free body stand approac...\n",
       "4    Control skin fall. Left worker ready take prop...\n",
       "Name: message_body, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the HTLM tags\n",
    "def remove_html_tags(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "df['message_body'] = df['message_body'].apply(remove_html_tags)\n",
    "df['message_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bb5cd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reflect available century join outside i cant ...\n",
       "1    Try cause behind single project Sport sound cl...\n",
       "2    While travel major strong pull Us history ligh...\n",
       "3    Can nothing force move free body stand approac...\n",
       "4    Control skin fall Left worker ready take prope...\n",
       "Name: message_body, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove repeated punctuation and special characters \n",
    "def remove_special_characters(text):    \n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "df['message_body'] = df['message_body'].apply(remove_special_characters)\n",
    "df['message_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72103b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reflect available century join outside i cant ...\n",
       "1    Try cause behind single project Sport sound cl...\n",
       "2    While travel major strong pull Us history ligh...\n",
       "3    Can nothing force move free body stand approac...\n",
       "4    Control skin fall Left worker ready take prope...\n",
       "Name: message_body, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove space extra spaces\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "df['message_body'] = df['message_body'].apply(remove_extra_spaces)\n",
    "df['message_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bebc9dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Reflect available century join outside i can l...\n",
       "1    Cry cause behind single project Port sound cle...\n",
       "2    While travel major strong pull Is history ligh...\n",
       "3    An nothing force move free body stand approach...\n",
       "4    Control skin fall Left worker ready take prope...\n",
       "Name: message_body, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix spelling mistakes\n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())\n",
    "df['message_body'] = df['message_body'].apply(correct_spelling)\n",
    "df['message_body'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f8f05",
   "metadata": {},
   "source": [
    "Perform text preprocessing — apply tokenization, lowercasing, lemmatization, and POS tagging using spaCy or NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee2a4c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_body</th>\n",
       "      <th>tokenized_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reflect available century join outside i can l...</td>\n",
       "      <td>[Reflect, available, century, join, outside, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cry cause behind single project Port sound cle...</td>\n",
       "      <td>[Cry, cause, behind, single, project, Port, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While travel major strong pull Is history ligh...</td>\n",
       "      <td>[While, travel, major, strong, pull, Is, histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An nothing force move free body stand approach...</td>\n",
       "      <td>[An, nothing, force, move, free, body, stand, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control skin fall Left worker ready take prope...</td>\n",
       "      <td>[Control, skin, fall, Left, worker, ready, tak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        message_body                                  tokenized_message\n",
       "0  Reflect available century join outside i can l...  [Reflect, available, century, join, outside, i...\n",
       "1  Cry cause behind single project Port sound cle...  [Cry, cause, behind, single, project, Port, so...\n",
       "2  While travel major strong pull Is history ligh...  [While, travel, major, strong, pull, Is, histo...\n",
       "3  An nothing force move free body stand approach...  [An, nothing, force, move, free, body, stand, ...\n",
       "4  Control skin fall Left worker ready take prope...  [Control, skin, fall, Left, worker, ready, tak..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply tokenisation\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "df['tokenized_message'] = df['message_body'].apply(tokenize_text)\n",
    "df[['message_body', 'tokenized_message']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "710f0026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    reflect available century join outside i can l...\n",
       "1    cry cause behind single project port sound cle...\n",
       "2    while travel major strong pull is history ligh...\n",
       "3    an nothing force move free body stand approach...\n",
       "4    control skin fall left worker ready take prope...\n",
       "Name: message_body, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercasing the text\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "df['message_body'] = df['message_body'].apply(lowercase_text)\n",
    "df['message_body'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e76325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "df['lemmatized_message'] = df['message_body'].apply(lemmatize_text)\n",
    "df[['message_body', 'lemmatized_message']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0df9f82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_body</th>\n",
       "      <th>pos_tagged_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reflect available century join outside i can l...</td>\n",
       "      <td>[(reflect, NN), (available, JJ), (century, NN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cry cause behind single project port sound cle...</td>\n",
       "      <td>[(cry, NN), (cause, NN), (behind, IN), (single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>while travel major strong pull is history ligh...</td>\n",
       "      <td>[(while, IN), (travel, NN), (major, JJ), (stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an nothing force move free body stand approach...</td>\n",
       "      <td>[(an, DT), (nothing, NN), (force, NN), (move, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>control skin fall left worker ready take prope...</td>\n",
       "      <td>[(control, NN), (skin, NN), (fall, NN), (left,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        message_body                                 pos_tagged_message\n",
       "0  reflect available century join outside i can l...  [(reflect, NN), (available, JJ), (century, NN)...\n",
       "1  cry cause behind single project port sound cle...  [(cry, NN), (cause, NN), (behind, IN), (single...\n",
       "2  while travel major strong pull is history ligh...  [(while, IN), (travel, NN), (major, JJ), (stro...\n",
       "3  an nothing force move free body stand approach...  [(an, DT), (nothing, NN), (force, NN), (move, ...\n",
       "4  control skin fall left worker ready take prope...  [(control, NN), (skin, NN), (fall, NN), (left,..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pos tagging\n",
    "def pos_tagging(text): \n",
    "    tokens = word_tokenize(text)\n",
    "    return pos_tag(tokens)\n",
    "df['pos_tagged_message'] = df['message_body'].apply(pos_tagging)\n",
    "df[['message_body', 'pos_tagged_message']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf4196",
   "metadata": {},
   "source": [
    "Extract key entities using Named Entity Recognition (NER) to identify product names, user names, locations, and issue types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "429d0d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_body</th>\n",
       "      <th>key_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reflect available century join outside i can l...</td>\n",
       "      <td>{'products': [], 'user_names': [], 'locations'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cry cause behind single project port sound cle...</td>\n",
       "      <td>{'products': [], 'user_names': [], 'locations'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>while travel major strong pull is history ligh...</td>\n",
       "      <td>{'products': [], 'user_names': [], 'locations'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an nothing force move free body stand approach...</td>\n",
       "      <td>{'products': [], 'user_names': [], 'locations'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>control skin fall left worker ready take prope...</td>\n",
       "      <td>{'products': [], 'user_names': [], 'locations'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        message_body                                       key_entities\n",
       "0  reflect available century join outside i can l...  {'products': [], 'user_names': [], 'locations'...\n",
       "1  cry cause behind single project port sound cle...  {'products': [], 'user_names': [], 'locations'...\n",
       "2  while travel major strong pull is history ligh...  {'products': [], 'user_names': [], 'locations'...\n",
       "3  an nothing force move free body stand approach...  {'products': [], 'user_names': [], 'locations'...\n",
       "4  control skin fall left worker ready take prope...  {'products': [], 'user_names': [], 'locations'..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_key_entities(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {\n",
    "            \"products\": [],\n",
    "            \"user_names\": [],\n",
    "            \"locations\": [],\n",
    "            \"issue_types\": []\n",
    "        }\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    products = [ent.text for ent in doc.ents if ent.label_ == \"PRODUCT\"]\n",
    "    user_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
    "    issue_types = [ent.text for ent in doc.ents if ent.label_ == \"  NORP\"]  \n",
    "\n",
    "    return {\n",
    "        \"products\": products,\n",
    "        \"user_names\": user_names,\n",
    "        \"locations\": locations,\n",
    "        \"issue_types\": issue_types\n",
    "    }\n",
    "df['key_entities'] = df['message_body'].apply(extract_key_entities)\n",
    "df[['message_body', 'key_entities']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425a3f1",
   "metadata": {},
   "source": [
    "Classify each message into categories such as Complaint, Bug Report, Feature Request, Praise, etc., using either traditional ML models or transformer-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a88ea9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_body</th>\n",
       "      <th>message_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reflect available century join outside i can l...</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cry cause behind single project port sound cle...</td>\n",
       "      <td>Feature Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>while travel major strong pull is history ligh...</td>\n",
       "      <td>Praise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an nothing force move free body stand approach...</td>\n",
       "      <td>Bug Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>control skin fall left worker ready take prope...</td>\n",
       "      <td>Praise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        message_body message_category\n",
       "0  reflect available century join outside i can l...  Feature Request\n",
       "1  cry cause behind single project port sound cle...  Feature Request\n",
       "2  while travel major strong pull is history ligh...           Praise\n",
       "3  an nothing force move free body stand approach...       Bug Report\n",
       "4  control skin fall left worker ready take prope...           Praise"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify each message into categories\n",
    "def classify_message(text):\n",
    "    text = text.lower()\n",
    "    if \"billing\" in text or \"invoice\" in text or \"payment\" in text:\n",
    "        return \"Complaint\"\n",
    "    elif \"technical\" in text or \"error\" in text or \"bug\" in text:\n",
    "        return \"Bug Report\"\n",
    "    elif \"account\" in text or \"login\" in text or \"password\" in text:\n",
    "        return \"Feature Request\"\n",
    "    else:\n",
    "        return \"Praise\"\n",
    "    \n",
    "df['message_category'] = df['message_body'].apply(classify_message)\n",
    "df[['message_body', 'message_category']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "98b6657c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4239114422.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom transformers import pipeline (classification, model = 'bert-large-cased-finetuned-conll03-english')\u001b[39m\n                                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline (classification, model = 'bert-large-cased-finetuned-conll03-english')\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model='bert-large-cased-finetuned-conll03-english', grouped_entities=True)\n",
    "\n",
    "def transformer_ner(text):\n",
    "    return ner_pipeline(text)\n",
    "\n",
    "df['transformer_ner'] = df['message_body'].apply(transformer_ner)\n",
    "df[['message_body', 'transformer_ner']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "362161a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'torchpipeline' from 'transformers' (C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ...existing code...\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m torchpipeline\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# use a valid model id on the Hub; e.g. dbmdz/bert-large-cased-finetuned-conll03-english\u001b[39;00m\n\u001b[32m      5\u001b[39m ner_pipeline = pipeline(\u001b[33m\"\u001b[39m\u001b[33mner\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mdbmdz/bert-large-cased-finetuned-conll03-english\u001b[39m\u001b[33m\"\u001b[39m, grouped_entities=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'torchpipeline' from 'transformers' (C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from transformers import torchpipeline\n",
    "\n",
    "# use a valid model id on the Hub; e.g. dbmdz/bert-large-cased-finetuned-conll03-english\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
    "\n",
    "def transformer_ner(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return []\n",
    "    return ner_pipeline(text)\n",
    "\n",
    "df['transformer_ner'] = df['message_body'].apply(transformer_ner)\n",
    "df[['message_body', 'transformer_ner']].head()\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a60c92",
   "metadata": {},
   "source": [
    "Summarize lengthy messages — for messages exceeding 100 words, apply text summarization using pretrained models like T5 or BART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "799625ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m summarizer = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msummarization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mt5-base\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msummarize_text\u001b[39m(text):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m summarizer(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\pipelines\\__init__.py:1017\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1012\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1013\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mYou cannot use both `pipeline(... dtype=..., model_kwargs=\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:...})` as those\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1014\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m arguments might conflict, use only one.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1015\u001b[39m         )\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m, dtype):\n\u001b[32m   1018\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(torch, dtype)\n\u001b[32m   1019\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m] = dtype\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\",model=\"t5-base\")\n",
    "def summarize_text(text):\n",
    "    return summarizer(text)\n",
    "\n",
    "df['summary'] = df['message_body'].apply(summarize_text)\n",
    "df[['message_body', 'summary']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeede67f",
   "metadata": {},
   "source": [
    "Generate an output CSV file containing the cleaned text, predicted category, extracted entities, and summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate csv file\n",
    "df.to_csv(\"C:\\\\Users\\\\admin\\\\OneDrive - BOMBAY COATED AND SPECIAL STEELS PRIVATE LIMITED\\\\Desktop\\\\customer_support_ticket_analyzer\\\\data\\\\processed_customer_support_tickets.csv\", index=False)\n",
    "if os.path.exists(\"C:\\\\Users\\\\admin\\\\OneDrive - BOMBAY COATED AND SPECIAL STEELS PRIVATE LIMITED\\\\Desktop\\\\customer_support_ticket_analyzer\\\\data\\\\processed_customer_support_tickets.csv\"):\n",
    "    print(\"CSV file generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8989c",
   "metadata": {},
   "source": [
    "(Optional) Develop an interactive app using Streamlit or Gradio, with filters for category, city, or keyword-based search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
